trainer {
  block_size: 256
  procs_per_trainer: 0
}
model {
  data_layout: "data_parallel"
  mini_batch_size: 11
  num_epochs: 0
  num_parallel_readers: 0

  ###################################################
  # Objective function and metrics
  ###################################################

  objective_function {
    layer_term { layer: "l2" }
  }
  metric {
    layer_metric {
      layer: "l2"
      name: "L2 norm"
    }
  }

  ###################################################
  # Callbacks
  ###################################################

  callback { print {} }
  callback { timer {} }
  callback {
    check_metric {
      metric: "L2 norm" # Expected value: 8.486
      lower_bound: 8.485
      upper_bound: 8.487
      error_on_failure: true
      execution_modes: "test"
    }
  }
  callback {
    check_gradients {
      verbose: false
      error_on_failure: true
    }
  }

  ###################################################
  # Layers
  ###################################################

  layer {
    name: "data"
    data_layout: "data_parallel"
    input {}
  }

  # Input data
  layer {
    name: "x"
    weights_layer {
      dims: "5"
    }
    data_layout: "model_parallel"
    weights: "x_vals"
  }
  weights {
    name: "x_vals"
    value_initializer {
      values: "-200 -0.25 0 0.5 100"
    }
  }

  # Variations of softsign layer
  layer {
    parents: "x"
    name: "softsign_model_parallel"
    softsign {}
    data_layout: "model_parallel"
  }
  layer {
    parents: "x"
    name: "softsign_data_parallel"
    softsign {}
    data_layout: "data_parallel"
  }

  # Combine into objective function
  layer {
    parents: "softsign_model_parallel softsign_data_parallel"
    name: "sum"
    sum {}
  }
  layer {
    parents: "sum"
    name: "l2"
    l2_norm2 {}
  }

}
