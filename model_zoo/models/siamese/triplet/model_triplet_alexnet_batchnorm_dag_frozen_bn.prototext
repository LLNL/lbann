model {
  data_layout: "data_parallel"
  mini_batch_size: 128
  block_size: 256
  num_epochs: 1
  num_parallel_readers: 0
  procs_per_trainer: 0

  ###################################################
  # Objective function
  ###################################################

  objective_function {
    layer_term { layer: "cross_entropy" }
    l2_weight_regularization {
      scale_factor: 0.0005
    }
  }

  ###################################################
  # Metrics
  ###################################################

  metric {
    layer_metric {
      name: "categorical accuracy"
      layer: "top1_accuracy"
      unit: "%"
    }
  }
  metric {
    layer_metric {
      name: "top-2 categorical accuracy"
      layer: "top2_accuracy"
      unit: "%"
    }
  }

  ###################################################
  # Callbacks
  ###################################################
  callback {
    imcomm {
      intertrainer_comm_method: "normal"
      all_optimizers: true
    }
  }
  callback { print {} }
  callback { timer {} }
  callback {
    poly_learning_rate {
      power: 0.5
    }
  }
  callback {
    checkpoint {
      checkpoint_dir: "pretrain-stage12"
      checkpoint_epochs: 1
      checkpoint_steps: 5000
    }
  }

  ###################################################
  # start of weights
  ###################################################
  # In general it is not necessary to explicitly describe weights whether they are shared or not.
  # Here, we do so to apply a specific initialization method for each weight.

  weights {
    name: "conv1_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.007
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv1_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv2_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.008
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv2_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv3_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.009
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv3_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv4_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv4_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv5_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.009
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv5_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc6_linearity"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.005
    }
    optimizer {
      sgd {
        learn_rate: 0.008
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc6_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc7_linearity"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.007
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc7_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc8_linearity"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.006
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc8_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc9_linearity"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.005
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc9_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  ###################################################################
  # weights of batch normalization layers shared among Siamese heads
  ###################################################################

  weights {
    name: "bn_conv1_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv1_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv1_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv1_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv2_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv2_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv2_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv2_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv3_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv3_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv3_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv3_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv4_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv4_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv4_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv4_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv5_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv5_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv5_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv5_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_fc6_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_fc6_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_fc6_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_fc6_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }

  ###################################################
  # start of layers
  ###################################################

  layer {
    name: "input"
    children: "slice label"
    data_layout: "data_parallel"
    input {}
  }
  layer {
    parents: "input"
    name: "slice"
    children: "conv1_head0 conv1_head1 conv1_head2"
    data_layout: "data_parallel"
    slice {
      axis: 0
      slice_points: "0 3 6 9"
    }
  }
  layer {
    parents: "input"
    name: "label"
    data_layout: "data_parallel"
    split {}
  }

  #### Siamese head 0 begins ####

  layer {
    parents: "slice"
    name: "conv1_head0"
    children: "bn_conv1_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 96
      conv_dims: "11 11"
      conv_pads: "0 0"
      conv_strides: "4 4"
      has_bias: true
      has_vectors: true
    }
    weights: "conv1_kernel conv1_bias"
  }

  layer {
    parents: "conv1_head0"
    name: "bn_conv1_head0"
    children: "relu1_head0"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv1_scale bn_conv1_bias bn_conv1_running_mean bn_conv1_running_variance"
  }

  layer {
    parents: "bn_conv1_head0"
    name: "relu1_head0"
    children: "pool1_head0"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu1_head0"
    name: "pool1_head0"
    children: "conv2_head0"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool1_head0"
    name: "conv2_head0"
    children: "bn_conv2_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 256
      conv_dims: "5 5"
      conv_pads: "2 2"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv2_kernel conv2_bias"
  }

  layer {
    parents: "conv2_head0"
    name: "bn_conv2_head0"
    children: "relu2_head0"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv2_scale bn_conv2_bias bn_conv2_running_mean bn_conv2_running_variance"
  }

  layer {
    parents: "bn_conv2_head0"
    name: "relu2_head0"
    children: "pool2_head0"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu2_head0"
    name: "pool2_head0"
    children: "conv3_head0"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool2_head0"
    name: "conv3_head0"
    children: "bn_conv3_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv3_kernel conv3_bias"
  }

  layer {
    parents: "conv3_head0"
    name: "bn_conv3_head0"
    children: "relu3_head0"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv3_scale bn_conv3_bias bn_conv3_running_mean bn_conv3_running_variance"
  }

  layer {
    parents: "bn_conv3_head0"
    name: "relu3_head0"
    children: "conv4_head0"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu3_head0"
    name: "conv4_head0"
    children: "bn_conv4_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv4_kernel conv4_bias"
  }

  layer {
    parents: "conv4_head0"
    name: "bn_conv4_head0"
    children: "relu4_head0"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv4_scale bn_conv4_bias bn_conv4_running_mean bn_conv4_running_variance"
  }

  layer {
    parents: "bn_conv4_head0"
    name: "relu4_head0"
    children: "conv5_head0"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu4_head0"
    name: "conv5_head0"
    children: "bn_conv5_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  256
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv5_kernel conv5_bias"
  }

  layer {
    parents: "conv5_head0"
    name: "bn_conv5_head0"
    children: "relu5_head0"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv5_scale bn_conv5_bias bn_conv5_running_mean bn_conv5_running_variance"
  }

  layer {
    parents: "bn_conv5_head0"
    name: "relu5_head0"
    children: "pool3_head0"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu5_head0"
    name: "pool3_head0"
    children: "fc6_head0"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool3_head0"
    name: "fc6_head0"
    children: "bn_fc6_head0"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 4096
      has_bias: true
    }
    weights: "fc6_linearity fc6_bias"
  }

  layer {
    parents: "fc6_head0"
    name: "bn_fc6_head0"
    children: "relu6_head0"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_fc6_scale bn_fc6_bias bn_fc6_running_mean bn_fc6_running_variance"
  }

  layer {
    parents: "bn_fc6_head0"
    name: "relu6_head0"
    children: "concatenation"
    data_layout: "data_parallel"
    relu {}
  }

  #### Siamese head 0 ends ####

  #### Siamese head 1 begins ####

  layer {
    parents: "slice"
    name: "conv1_head1"
    children: "bn_conv1_head1"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 96
      conv_dims: "11 11"
      conv_pads: "0 0"
      conv_strides: "4 4"
      has_bias: true
      has_vectors: true
    }
    weights: "conv1_kernel conv1_bias"
  }

  layer {
    parents: "conv1_head1"
    name: "bn_conv1_head1"
    children: "relu1_head1"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv1_scale bn_conv1_bias bn_conv1_running_mean bn_conv1_running_variance"
  }

  layer {
    parents: "bn_conv1_head1"
    name: "relu1_head1"
    children: "pool1_head1"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu1_head1"
    name: "pool1_head1"
    children: "conv2_head1"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool1_head1"
    name: "conv2_head1"
    children: "bn_conv2_head1"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 256
      conv_dims: "5 5"
      conv_pads: "2 2"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv2_kernel conv2_bias"
  }

  layer {
    parents: "conv2_head1"
    name: "bn_conv2_head1"
    children: "relu2_head1"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv2_scale bn_conv2_bias bn_conv2_running_mean bn_conv2_running_variance"
  }

  layer {
    parents: "bn_conv2_head1"
    name: "relu2_head1"
    children: "pool2_head1"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu2_head1"
    name: "pool2_head1"
    children: "conv3_head1"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool2_head1"
    name: "conv3_head1"
    children: "bn_conv3_head1"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv3_kernel conv3_bias"
  }

  layer {
    parents: "conv3_head1"
    name: "bn_conv3_head1"
    children: "relu3_head1"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv3_scale bn_conv3_bias bn_conv3_running_mean bn_conv3_running_variance"
  }

  layer {
    parents: "bn_conv3_head1"
    name: "relu3_head1"
    children: "conv4_head1"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu3_head1"
    name: "conv4_head1"
    children: "bn_conv4_head1"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv4_kernel conv4_bias"
  }

  layer {
    parents: "conv4_head1"
    name: "bn_conv4_head1"
    children: "relu4_head1"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv4_scale bn_conv4_bias bn_conv4_running_mean bn_conv4_running_variance"
  }

  layer {
    parents: "bn_conv4_head1"
    name: "relu4_head1"
    children: "conv5_head1"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu4_head1"
    name: "conv5_head1"
    children: "bn_conv5_head1"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  256
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv5_kernel conv5_bias"
  }

  layer {
    parents: "conv5_head1"
    name: "bn_conv5_head1"
    children: "relu5_head1"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv5_scale bn_conv5_bias bn_conv5_running_mean bn_conv5_running_variance"
  }

  layer {
    parents: "bn_conv5_head1"
    name: "relu5_head1"
    children: "pool3_head1"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu5_head1"
    name: "pool3_head1"
    children: "fc6_head1"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool3_head1"
    name: "fc6_head1"
    children: "bn_fc6_head1"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 4096
      has_bias: true
    }
    weights: "fc6_linearity fc6_bias"
  }

  layer {
    parents: "fc6_head1"
    name: "bn_fc6_head1"
    children: "relu6_head1"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_fc6_scale bn_fc6_bias bn_fc6_running_mean bn_fc6_running_variance"
  }

  layer {
    parents: "bn_fc6_head1"
    name: "relu6_head1"
    children: "concatenation"
    data_layout: "data_parallel"
    relu {}
  }

  #### Siamese head 1 ends ####

  #### Siamese head 2 begins ####

  layer {
    parents: "slice"
    name: "conv1_head2"
    children: "bn_conv1_head2"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 96
      conv_dims: "11 11"
      conv_pads: "0 0"
      conv_strides: "4 4"
      has_bias: true
      has_vectors: true
    }
    weights: "conv1_kernel conv1_bias"
  }

  layer {
    parents: "conv1_head2"
    name: "bn_conv1_head2"
    children: "relu1_head2"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv1_scale bn_conv1_bias bn_conv1_running_mean bn_conv1_running_variance"
  }

  layer {
    parents: "bn_conv1_head2"
    name: "relu1_head2"
    children: "pool1_head2"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu1_head2"
    name: "pool1_head2"
    children: "conv2_head2"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool1_head2"
    name: "conv2_head2"
    children: "bn_conv2_head2"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 256
      conv_dims: "5 5"
      conv_pads: "2 2"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv2_kernel conv2_bias"
  }

  layer {
    parents: "conv2_head2"
    name: "bn_conv2_head2"
    children: "relu2_head2"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv2_scale bn_conv2_bias bn_conv2_running_mean bn_conv2_running_variance"
  }

  layer {
    parents: "bn_conv2_head2"
    name: "relu2_head2"
    children: "pool2_head2"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu2_head2"
    name: "pool2_head2"
    children: "conv3_head2"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool2_head2"
    name: "conv3_head2"
    children: "bn_conv3_head2"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv3_kernel conv3_bias"
  }

  layer {
    parents: "conv3_head2"
    name: "bn_conv3_head2"
    children: "relu3_head2"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv3_scale bn_conv3_bias bn_conv3_running_mean bn_conv3_running_variance"
  }

  layer {
    parents: "bn_conv3_head2"
    name: "relu3_head2"
    children: "conv4_head2"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu3_head2"
    name: "conv4_head2"
    children: "bn_conv4_head2"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv4_kernel conv4_bias"
  }

  layer {
    parents: "conv4_head2"
    name: "bn_conv4_head2"
    children: "relu4_head2"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv4_scale bn_conv4_bias bn_conv4_running_mean bn_conv4_running_variance"
  }

  layer {
    parents: "bn_conv4_head2"
    name: "relu4_head2"
    children: "conv5_head2"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu4_head2"
    name: "conv5_head2"
    children: "bn_conv5_head2"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  256
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv5_kernel conv5_bias"
  }

  layer {
    parents: "conv5_head2"
    name: "bn_conv5_head2"
    children: "relu5_head2"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv5_scale bn_conv5_bias bn_conv5_running_mean bn_conv5_running_variance"
  }

  layer {
    parents: "bn_conv5_head2"
    name: "relu5_head2"
    children: "pool3_head2"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu5_head2"
    name: "pool3_head2"
    children: "fc6_head2"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool3_head2"
    name: "fc6_head2"
    children: "bn_fc6_head2"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 4096
      has_bias: true
    }
    weights: "fc6_linearity fc6_bias"
  }

  layer {
    parents: "fc6_head2"
    name: "bn_fc6_head2"
    children: "relu6_head2"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_fc6_scale bn_fc6_bias bn_fc6_running_mean bn_fc6_running_variance"
  }

  layer {
    parents: "bn_fc6_head2"
    name: "relu6_head2"
    children: "concatenation"
    data_layout: "data_parallel"
    relu {}
  }

  #### Siamese head 2 ends ####

  layer {
    parents: "relu6_head0 relu6_head1 relu6_head2"
    name: "concatenation"
    children: "fc7"
    data_layout: "data_parallel"
    concatenation {}
  }

  layer {
    parents: "concatenation"
    name: "fc7"
    children: "bn_fc7"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 4096
      has_bias: true
    }
    weights: "fc7_linearity fc7_bias"
  }

  layer {
    parents: "fc7"
    name: "bn_fc7"
    children: "relu7"
    data_layout: "data_parallel"
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
  }

  layer {
    parents: "bn_fc7"
    name: "relu7"
    children: "fc8"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu7"
    name: "fc8"
    children: "bn_fc8"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 4096
      has_bias: true
    }
    weights: "fc8_linearity fc8_bias"
  }

  layer {
    parents: "fc8"
    name: "bn_fc8"
    children: "relu8"
    data_layout: "data_parallel"
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
  }

  layer {
    parents: "bn_fc8"
    name: "relu8"
    children: "fc9"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu8"
    name: "fc9"
    children: "prob"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons_is_num_labels: true
      has_bias: false
    }
    weights: "fc9_linearity fc9_bias"
  }

  layer {
    parents: "fc9"
    name: "prob"
    data_layout: "data_parallel"
    softmax {}
  }

  layer {
    parents: "prob label"
    name: "cross_entropy"
    data_layout: "data_parallel"
    cross_entropy {}
  }
  layer {
    parents: "prob label"
    name: "top1_accuracy"
    data_layout: "data_parallel"
    categorical_accuracy {}
  }
  layer {
    parents: "prob label"
    name: "top2_accuracy"
    data_layout: "data_parallel"
    top_k_categorical_accuracy { k: 2 }
  }

}
