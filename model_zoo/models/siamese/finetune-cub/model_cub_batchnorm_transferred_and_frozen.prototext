model {
  data_layout: "data_parallel"
  mini_batch_size: 64
  block_size: 256
  num_epochs: 50
  num_parallel_readers: 0
  procs_per_trainer: 0

  ###################################################
  # Objective function
  ###################################################

  objective_function {
    layer_term { layer: "cross_entropy_new" }
    l2_weight_regularization {
      scale_factor: 0.0005
    }
  }

  ###################################################
  # Metrics
  ###################################################

  metric {
    layer_metric {
      name: "categorical accuracy"
      layer: "top1_accuracy_new"
      unit: "%"
    }
  }
  metric {
    layer_metric {
      name: "top-5 categorical accuracy"
      layer: "top5_accuracy_new"
      unit: "%"
    }
  }

  ###################################################
  # Callbacks
  ###################################################
  callback {
    imcomm {
      intertrainer_comm_method: "normal"
      all_optimizers: true
    }
  }
  callback { print {} }
  callback { timer {} }
  callback {
    poly_learning_rate {
      power: 0.5
    }
  }

  ###################################################
  # start of weights
  ###################################################

  # The weights of the layers conv1_head0, conv2_head0, conv3_head0, conv4_head0, and conv5_head0
  # will be initialized as described here but overwritten with pretrained ones.
  # The optimizer states may not be transferred if lbann2 is used.
  # The weights of the rest learning layers will be initialized as described below and trained fresh.

  weights {
    name: "conv1_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv1_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv2_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv2_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv3_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv3_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv4_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv4_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv5_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv5_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv6_new_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv6_new_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv6b_new_kernel"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv6b_new_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc7_new_linearity"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.005
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc7_new_bias"
    constant_initializer {
      value: 0.1
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc8_new_linearity"
    normal_initializer {
      mean: 0.0
      standard_deviation: 0.01
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc8_new_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  ###################################################################
  # weights of batch normalization layers shared among Siamese heads
  ###################################################################

  weights {
    name: "bn_conv1_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv1_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv1_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv1_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv2_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv2_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv2_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv2_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv3_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv3_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv3_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv3_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv4_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv4_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv4_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv4_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv5_scale"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv5_bias"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv5_running_mean"
    constant_initializer {
      value: 0.0
    }
    optimizer {}
  }


  weights {
    name: "bn_conv5_running_variance"
    constant_initializer {
      value: 1.0
    }
    optimizer {}
  }


  ###################################################
  # start of replicate layers
  ###################################################

  layer {
    name: "input_new"
    children: "data_new label_new"
    data_layout: "data_parallel"
    input {}
  }
  layer {
    parents: "input_new"
    name: "data_new"
    data_layout: "data_parallel"
    split {}
  }
  layer {
    parents: "input_new"
    name: "label_new"
    data_layout: "data_parallel"
    split {}
  }

  layer {
    parents: "data_new"
    name: "conv1_head0"
    children: "bn_conv1_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 96
      conv_dims: "11 11"
      conv_pads: "5 5"
      conv_strides: "4 4"
      has_bias: true
      has_vectors: true
    }
    weights: "conv1_kernel conv1_bias"
  }

  layer {
    parents: "conv1_head0"
    name: "bn_conv1_head0"
    children: "relu1_new"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv1_scale bn_conv1_bias bn_conv1_running_mean bn_conv1_running_variance"
  }

  layer {
    parents: "bn_conv1_head0"
    name: "relu1_new"
    children: "pool1_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu1_new"
    name: "pool1_new"
    children: "conv2_head0"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool1_new"
    name: "conv2_head0"
    children: "bn_conv2_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 256
      conv_dims: "5 5"
      conv_pads: "2 2"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv2_kernel conv2_bias"
  }

  layer {
    parents: "conv2_head0"
    name: "bn_conv2_head0"
    children: "relu2_new"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv2_scale bn_conv2_bias bn_conv2_running_mean bn_conv2_running_variance"
  }

  layer {
    parents: "bn_conv2_head0"
    name: "relu2_new"
    children: "pool2_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu2_new"
    name: "pool2_new"
    children: "conv3_head0"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool2_new"
    name: "conv3_head0"
    children: "bn_conv3_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv3_kernel conv3_bias"
  }

  layer {
    parents: "conv3_head0"
    name: "bn_conv3_head0"
    children: "relu3_new"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv3_scale bn_conv3_bias bn_conv3_running_mean bn_conv3_running_variance"
  }

  layer {
    parents: "bn_conv3_head0"
    name: "relu3_new"
    children: "conv4_head0"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu3_new"
    name: "conv4_head0"
    children: "bn_conv4_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv4_kernel conv4_bias"
  }

  layer {
    parents: "conv4_head0"
    name: "bn_conv4_head0"
    children: "relu4_new"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv4_scale bn_conv4_bias bn_conv4_running_mean bn_conv4_running_variance"
  }

  layer {
    parents: "bn_conv4_head0"
    name: "relu4_new"
    children: "conv5_head0"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu4_new"
    name: "conv5_head0"
    children: "bn_conv5_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  256
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv5_kernel conv5_bias"
  }

  layer {
    parents: "conv5_head0"
    name: "bn_conv5_head0"
    children: "relu5_new"
    data_layout: "data_parallel"
    freeze: true
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
    weights: "bn_conv5_scale bn_conv5_bias bn_conv5_running_mean bn_conv5_running_variance"
  }

  layer {
    parents: "bn_conv5_head0"
    name: "relu5_new"
    children: "pool5_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu5_new"
    name: "pool5_new"
    children: "conv6_new"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  ###################################################
  # end of replicate layers
  ###################################################
  ######################################
  # Start of Doersch Layer 6
  ######################################

  layer {
    parents: "pool5_new"
    name: "conv6_new"
    children: "bn_conv6_new"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  4096
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv6_new_kernel conv6_new_bias"
  }

  layer {
    parents: "conv6_new"
    name: "bn_conv6_new"
    children: "relu6_new"
    data_layout: "data_parallel"
    freeze: false
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
  }

  layer {
    parents: "bn_conv6_new"
    name: "relu6_new"
    children: "conv6b_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu6_new"
    name: "conv6b_new"
    children: "bn_conv6b_new"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  1024
      conv_dims: "1 1"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv6b_new_kernel conv6b_new_bias"
  }

  layer {
    parents: "conv6b_new"
    name: "bn_conv6b_new"
    children: "relu6b_new"
    data_layout: "data_parallel"
    freeze: false
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
  }

  layer {
    parents: "bn_conv6b_new"
    name: "relu6b_new"
    children: "pool6_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu6b_new"
    name: "pool6_new"
    children: "fc7_new"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  ######################################
  # End of Doersch Layer 6
  ######################################

  layer {
    parents: "pool6_new"
    name: "fc7_new"
    children: "bn_fc7_new"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 4096
      has_bias: true
    }
    weights: "fc7_new_linearity fc7_new_bias"
  }

  layer {
    parents: "fc7_new"
    name: "bn_fc7_new"
    children: "relu7_new"
    data_layout: "data_parallel"
    freeze: false
    batch_normalization {
      decay: 0.9
      scale_init: 1.0
      bias_init: 0.0
      epsilon: 1e-5
      stats_aggregation: "global"
    }
  }

  layer {
    parents: "bn_fc7_new"
    name: "relu7_new"
    children: "drop7_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu7_new"
    name: "drop7_new"
    children: "fc8_new"
    data_layout: "data_parallel"
    dropout {
      keep_prob: 0.9
    }
  }

  layer {
    parents: "drop7_new"
    name: "fc8_new"
    children: "prob_new"
    data_layout: "data_parallel"
    fully_connected {
      # The number of outputs specific to the dataset used.
      # E.g., 200 for CUB, and 431 for CompCars.
      num_neurons_is_num_labels: true
      has_bias: false
    }
    weights: "fc8_new_linearity fc8_new_bias"
  }

  layer {
    parents: "fc8_new"
    name: "prob_new"
    data_layout: "data_parallel"
    softmax {}
  }

  layer {
    parents: "prob_new label_new"
    name: "cross_entropy_new"
    data_layout: "data_parallel"
    cross_entropy {}
  }
  layer {
    parents: "prob_new label_new"
    name: "top1_accuracy_new"
    data_layout: "data_parallel"
    categorical_accuracy {}
  }
  layer {
    parents: "prob_new label_new"
    name: "top5_accuracy_new"
    data_layout: "data_parallel"
    top_k_categorical_accuracy { k: 5 }
  }

}
