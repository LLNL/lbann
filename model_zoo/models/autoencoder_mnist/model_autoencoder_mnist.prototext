model {
  name: "sequential_model"
  data_layout: "model_parallel"
  mini_batch_size: 10
  block_size: 256
  num_epochs: 10
  num_parallel_readers: 0
  procs_per_model: 0
  use_cudnn: true
  num_gpus: -1

  ###################################################
  # Objective function
  ###################################################

  objective_function {
    mean_squared_error {}
  }

  ###################################################
  # Callbacks
  ###################################################
  callback {
    print {
      interval: 1
    }
  }
#  callback {
#    timer {
#    }
#  }
#  callback {
#    save_images {
#      image_dir: "images_"
#      extension: "pgm"
#    }
#  }

  ###################################################
  # start of layers
  ###################################################

  #######
  # INPUT
  #######
  layer {
    name: "data"
    data_layout: "model_parallel"
    input_distributed_minibatch {
    }
  }

  # FULLY_CONNECTED encode1
  #################
  layer {
    name: "encode1"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 1000
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  # RELU relu1
  ######
  layer {
    name: "relu1"
    data_layout: "model_parallel"
    relu {
    }
  }

  # FULLY_CONNECTED encode2
  #################
  layer {
    name: "encode2"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 500
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  # RELU relu2
  #######
  layer {
    name: "relu2"
    data_layout: "model_parallel"
    relu {
    }
  }

  # FULLY_CONNECTED encode3
  #################
  layer {
    name: "encode3"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 250
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  #######
  # RELU relu3
  #######
  layer {
    name: "relu3"
    data_layout: "model_parallel"
    relu {
    }
  }

  # FULLY_CONNECTED encode4
  #################
  layer {
    name: "encode4"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 30
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  # FULLY_CONNECTED decode4
  #################
  layer {
    name: "decode4"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 250
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  # RELU 4
  #######
  layer {
    name: "relu4"
    data_layout: "model_parallel"
    relu {
    }
  }

  # FULLY_CONNECTED decode3
  #################
  layer {
    name: "decode3"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 500
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }


  # RELU relu5
  #######
  layer {
    name: "relu5"
    data_layout: "model_parallel"
    relu {
    }
  }

  # FULLY_CONNECTED decode2
  #################
  layer {
    name: "decode2"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 1000
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  # RELU relu6
  #######
  layer {
    name: "relu6"
    data_layout: "model_parallel"
    relu {
    }
  }

  # FULLY_CONNECTED decode1
  #################
  layer {
    name: "decode1"
    data_layout: "model_parallel"
    num_neurons_from_data_reader: true
    fully_connected {
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  #######
  # SIGMOID sigmoid
  #######
  layer {
    name: "sigmoid"
    data_layout: "model_parallel"
    sigmoid {
    }
  }

  
  #################
  # RECONSTRUCTION
  #################
  layer {
    name: "reconstruction"
    data_layout: "model_parallel"
    reconstruction {
      original_layer: "data"
    }
  }

  ###################################################
  # end of layers
  ###################################################
}
