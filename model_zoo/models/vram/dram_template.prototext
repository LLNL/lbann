trainer {
  block_size: 256
  procs_per_trainer: 0
}
model {
  data_layout: "data_parallel"
  mini_batch_size: 256
  num_epochs: 20
  num_parallel_readers: 0

  ###################################################
  # Objective function
  ###################################################
  objective_function {
    l2_weight_regularization {
      scale_factor: 0.0005
    }
  }

  ###################################################
  # Callbacks
  ###################################################
  callback { print {} }
  callback { timer {} }

}
