syntax = "proto3";

package lbann_data;

message LbannPB {
  DataReader data_reader = 1; 
  Model model = 2; 
  Optimizer optimizer = 3;
}

//========================================================================
// DataReaders
//========================================================================
message DataReader {
  int64 max_par_io_size = 1;
  repeated Reader reader = 2;
}

message Reader {
  string name = 1; //mnist, nci, nci_regression, numpy, imagenet, synthetic
  string role = 3; //train, test
  bool shuffle = 4;
  string data_filedir = 5;
  string data_filename = 6;
  string label_filename = 7;
  double train_or_test_percent = 8;
  double validation_percent = 9;
  bool firstN = 10;
  int64 max_sample_count = 11;
  double percent_of_data_to_use = 12;
  ImagePreprocessor image_preprocessor = 13;
  int64 num_samples = 100; //only for synthetic
  int64 num_features = 101; //only for synthetic
  //csv attributes
  string separator = 102;
  int32 skip_cols = 103;
  int32 skip_rows = 104;
  bool has_header = 105;
  int32 label_col = 106;
  int32 response_col = 107;
  bool disable_labels = 108;
  bool disable_reponses = 109;
}

message ImagePreprocessor {
  bool scale = 12;
  bool subtract_mean = 13;
  bool unit_variance = 14;
  bool z_score = 15;
  bool horizontal_flip = 16;
  bool vertical_flip = 17;
  double rotation = 18;
  double horizontal_shift = 19;
  double vertical_shift = 20;
  double shear_range = 21;
  bool disable_augmentation = 22;
  float noise_factor = 23;
}

//========================================================================
// Model
//========================================================================

message Model {
  string name = 1; //dnn, greedy_layerwise_autoencoder
  string objective_function = 2; // cross_entropy, mean_squared_error
  repeated Metric metric = 5; 
  string data_layout = 6;

  int64 mini_batch_size = 12;
  int64 num_epochs = 4;
  int64 block_size = 50;
  int64 procs_per_model = 51;
  int64 num_gpus = 53;
  int64 evaluation_frequency = 54;
  int64 num_parallel_readers = 100;

  //use cudnn_manager, if use_cudnn=true AND lbann was compiled with cudnn support
  bool use_cudnn = 8;

  repeated Layer layer = 10;

  // checknan, debug, dump_activations, etc;
  // for complete list, see: lbann/include/lbann/callbacks
  repeated Callback callback = 20; 

  //checkpointing
  string checkpoint_dir = 30;
  int64 checkpoint_epochs = 31;
  int64 checkpoint_steps = 32;
  double checkpoint_secs = 33;
}

//========================================================================
// Metrics
//========================================================================

message Metric {
  // a Metric should contain exactly one of the following
  CategoricalAccuracy categorical_accuracy = 1;
  MeanSquaredError mean_squared_error = 2;
  TopKCategoricalAccuracy top_k_categorical_accuracy = 3;
}

message CategoricalAccuracy {
}

message MeanSquaredError {
}

message TopKCategoricalAccuracy {
  int64 top_k = 2; //only applicable for top_k_categorical_accuracy
}
  
//========================================================================
// Optimizers
//========================================================================
message Optimizer {
  // An Optimizer should contain exactly one of the following
  // (this may or may not be properly checked for in proto_common.cpp)
  Adagrad adagrad = 1;
  Rmsprop rmsprop = 2;
  Adam adam = 3;
  HypergradientAdam hypergradient_adam = 4;
  Sgd sgd = 5;
}

message Adagrad {
  double learn_rate = 1;
  double eps = 2;  //default: 1e-8 
}

message Adam {
  double learn_rate = 1;
  double beta1 = 6;    //default: 0.9
  double beta2 = 7;    //default: 0.99
  double eps = 8;      //default: 1e-8
}

message HypergradientAdam {
  double init_learning_rate = 1;
  double hyper_learning_rate = 2; //default: 1e-7
  double beta1 = 6;    //default: 0.9
  double beta2 = 7;    //default: 0.99
  double eps = 8;      //default: 1e-8
}

message Rmsprop {
  double learn_rate = 1;
  double decay_rate = 2;
  double eps = 3; //default: 1e-8
}

message Sgd {
  double learn_rate = 1;
  double momentum = 2;     //default: 0
  double decay_rate = 3;   //default: 0
  bool nesterov = 4;       //default: false
}


//========================================================================
// Callbacks
//========================================================================
message Callback {
   // a Callback should contain exactly one of the following
   CallbackPrint print = 1;
   CallbackTimer timer = 2;
   CallbackSummary summary = 3;
   CallbackDumpWeights dump_weights = 4;
   CallbackDumpActivations dump_activations = 5;
   CallbackDumpGradients dump_gradients = 6;
   CallbackDumpMBIndices dump_mb_indices = 7;
   CallbackDispIOStats disp_io_stats = 8;
   CallbackImComm imcomm = 9;
   CallbackSaveImages save_images = 10;
   CallbackDebug debug = 11;
   CallbackAdaptiveLearningRate adaptive_learning_rate = 12;
   CallbackStepLearningRate step_learning_rate = 13;
   CallbackCustomLearningRate custom_learning_rate = 14;
   CallbackCheckSmall check_small = 15;
   CallbackCheckNaN check_nan = 16;
   CallbackCheckDataset check_dataset = 17;
   CallbackHang hang = 18;
   CallbackDropFixedLearningRate drop_fixed_learning_rate = 19;
   CallbackLinearGrowthLearningRate linear_growth_learning_rate = 20;
   CallbackProfiler profiler = 21;
   CallbackStepMinibatch step_minibatch = 22;
   CallbackGradientCheck gradient_check = 23;
   CallbackLTFB ltfb = 24;
}

message CallbackLTFB {
  int64 round_size = 1;
}

message CallbackStepLearningRate {
  string layers = 1; //e.g: "1 5 6" use "10000" to apply to all layers
  int64 step = 2;
  double amt = 3;
}

message CallbackCustomLearningRate {
  //don't know how to support this, since it takes an std::function as an argument
}

message CallbackAdaptiveLearningRate {
  string layers = 1; //e.g: "1 5 6" use "10000" to apply to all layers
  int64 patience = 2;
  double amt = 3;
}

message CallbackSaveImages {
  string image_dir = 1;
  string extension = 2;
}

message CallbackPrint {
  int64 interval = 1; //default in lbann_callback_print.hpp is 1
}

message CallbackProfiler {
}

message CallbackTimer {
}

message CallbackSummary {
  string dir = 1; //directory for the lbann_summary
  int64 batch_interval = 2; //default in lbann_callback_summary.hpp is 1
  int64 mat_interval = 3; //default in lbann_callback_summary.hpp is 25
}

message CallbackDumpWeights {
  string basename = 1;
  int64 interval = 2;
}

message CallbackDumpActivations {
  string basename = 1;
  int64 interval = 2;
}

message CallbackDumpGradients {
  string basename = 1;
  int64 interval = 2;
}

message CallbackDumpMBIndices {
  string basename = 1;
  int64 interval = 2;
}

message CallbackDispIOStats {
  string layers = 1; //e.g: "2 4 5"; use "10000" to apply to all layers
}

message CallbackImComm {
  string intermodel_comm_method = 1;
  string layers = 2; //e.g: "2 4 5"; use "10000" to apply to all layers
}

message CallbackDebug {
  string phase = 1;
}

message CallbackCheckSmall {
}

message CallbackCheckNaN {
}

message CallbackCheckDataset {
}

message CallbackHang {
  int64 rank = 1;
}

message CallbackDropFixedLearningRate {
  repeated int64 layer = 1;
  repeated int64 drop_epoch = 2;
  double amt = 3;
}

message CallbackLinearGrowthLearningRate {
  repeated int64 layer = 1;
  double target = 2;
  int64 num_epochs = 3;
  int64 delay = 4;
}

message CallbackStepMinibatch {
  int64 starting_mbsize = 1;
  int64 step = 2;
}

message CallbackGradientCheck {
  double step_size = 1;
  bool verbose = 2;
  bool fail_on_error = 3;
}

//========================================================================
// Layers
//========================================================================
//
// weight initialization should be one of: 
//    zero, uniform, normal, glorot_normal, he_normal, he_uniform
// see: lbann/include/lbann/lbann_base.hpp
//

message Layer {
   int64 index = 50; 
   int64 parent = 51;
   string data_layout = 52;
   bool num_neurons_from_data_reader = 53;

   // a Layer should contain exactly one of the following
   // (this may or may not be properly checked for in proto_common.cpp)

   // input Layers
   InputDistributedMiniBatch input_distributed_minibatch = 2;
   InputPartitionedMiniBatch input_partitioned_minibatch = 3;

   // transform Layers
   Pooling pooling = 12;
   Concatenation concatenation = 300;
   Slice slice = 301;
   Split split = 302;
   Sum sum = 303;
   Unpooling unpooling = 304;

   // learning Layers
   FullyConnected fully_connected = 11;
   Convolution convolution = 13;
   Deconvolution deconvolution = 305;

   // target Layers
   TargetDistributedMinibatch target_distributed_minibatch = 18;
   TargetPartitionedMinibatch target_partitioned_minibatch = 180;
   TargetReconstruction reconstruction = 22;

   // regularization Layers
   BatchNormalization batch_normalization = 19;
   LocalResponseNormalization local_response_normalization = 20;
   Dropout dropout = 21;
   SeluDropout selu_dropout = 229;

   // activation Layers
   Softmax softmax = 200;
   ELU elu = 30;
   ID id = 31;
   LeakyRelu leaky_relu = 32;
   Relu relu = 33;
   Sigmoid sigmoid = 34;
   SmoothRelu smooth_relu = 35;
   Softplus softplus = 36;
   Selu selu = 37;
   Tanh tanh = 38;
}

///////////////////////
// Activation Layers //
///////////////////////
message ELU {
  double alpha = 2; //default: 1.0; must be >= 0
}

message ID {
}

message LeakyRelu {
  double leak = 2; //default: 0.01
}

message Relu {
}

message Sigmoid {
}

message SmoothRelu {
}

message Softplus {
}

message Tanh {
}

message Selu {
  double alpha = 2; //default: 1.6732632423543772848170429916717
  double scale = 3; //default: 1.0507009873554804934193349852946
}

message Softmax {
}

///////////////////////////
// Regularization Layers //
///////////////////////////
message BatchNormalization {
  double decay = 1;          //default: 0.9
  double scale_init = 2;     //default: 1.0
  double bias_init = 3;      //default: 0.0
  double epsilon = 4;        //default: 1e-5
  bool global_stats = 5;     //for future use
}

message SeluDropout {
  double keep_prob = 2; //default: 0.95
  double alpha = 3;     //default: 1.6732632423543772848170429916717
  double scale = 4;     //default: 1.0507009873554804934193349852946
}

message LocalResponseNormalization {
  int64 window_width = 4;
  double lrn_alpha = 5;
  double lrn_beta = 6;
  double lrn_k = 7;
}

message Dropout {
  double keep_prob = 2;  //default: 0.5
}

//////////////////
// Input Layers //
//////////////////
message InputDistributedMiniBatch {
}

message InputPartitionedMiniBatch {
}

//////////////////////
// transform Layers //
//////////////////////
message Pooling {
  int64 num_dims = 1;

  bool has_vectors = 2;

  //these are used if has_vectors = true
  string pool_dims = 4; //should be space-separated list, e.g, "2 2 3"
  string pool_pads = 5; //should be space-separated list, e.g, "2 2 3"
  string pool_strides = 6; //should be space-separated list, e.g, "2 2 3"

  //these are used if has_vectors = false
  int64 pool_dims_i = 10;
  int64 pool_pads_i = 11;
  int64 pool_strides_i = 12;

  //pool_mode should be one of: max, average, average_no_pad
  //see: lbann/include/lbann/lbann_base.hpp
  string pool_mode = 7;
}

message Unpooling {
  int64 num_dims = 1;
  int64 pooling_layer = 13; //should be index of pooling layer
}


message Concatenation {
  string parents = 1; //should be space-separated list of indices, e.g, "2 6 7"
  int64 concatenation_axis = 2;
}

message Slice {
  string children = 1; //should be space-separated list of indices, e.g, "2 6 7"
  int64 slice_axis = 2;
  string slice_points = 3; //should be space-separated list of ints, e.g, "2 6 7"
}

message Split {
  string children = 1; //should be space-separated list of indices, e.g, "2 6 7"
}

message Sum {
  string parents = 1; //should be space-separated list of indices, e.g, "2 6 7"
}

/////////////////////
// learning Layers //
/////////////////////
message FullyConnected {
  int64 num_neurons = 1;
  string weight_initialization = 2;
  bool has_bias = 3;                   //default: true
  double bias_initial_value = 4;       //default: 0
  double l2_regularization_factor = 5; //default: 0
}

message Convolution {
  int64 num_dims = 1;
  int64 num_output_channels = 4;

  bool has_vectors = 2;

  // these are used if has_vector = true
  string conv_dims = 5; //should be space-separated list, e.g, "2 2 3"
  string conv_pads = 6;  //should be space-separated list, e.g, "2 2 3"
  string conv_strides = 7; //should be space-separated list, e.g, "2 2 3"

  // these are used if has_vector = false
  int64 conv_dims_i = 50; 
  int64 conv_pads_i = 60; 
  int64 conv_strides_i = 70; 

  string weight_initialization = 9;
  bool has_bias = 10;                   //default: true
  double bias_initial_value = 11;       //default: 0
  double l2_regularization_factor = 12; //default: 0
}

message Deconvolution {
  int64 num_dims = 1;
  int64 num_output_channels = 4;

  bool has_vectors = 2;

  // these are used if has_vector = true
  string conv_dims = 5; //should be space-separated list, e.g, "2 2 3"
  string conv_pads = 6;  //should be space-separated list, e.g, "2 2 3"
  string conv_strides = 7; //should be space-separated list, e.g, "2 2 3"

  // these are used if has_vector = false
  int64 conv_dims_i = 50; 
  int64 conv_pads_i = 60; 
  int64 conv_strides_i = 70; 

  string weight_initialization = 9;
  bool has_bias = 10;                   //default: true
  double bias_initial_value = 11;       //default: 0
  double l2_regularization_factor = 12; //default: 0
}

///////////////////
// Target Layers //
///////////////////
message TargetDistributedMinibatch {
  bool shared_data_reader = 2;
  bool for_regression = 3; //default: false
}

message TargetPartitionedMinibatch {
  bool shared_data_reader = 2;
  bool for_regression = 3; //default: false
}

message TargetReconstruction {
  int64 original_layer = 1;
}

