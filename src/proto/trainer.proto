////////////////////////////////////////////////////////////////////////////////
// Copyright (c) 2014-2019, Lawrence Livermore National Security, LLC.
// Produced at the Lawrence Livermore National Laboratory.
// Written by the LBANN Research Team (B. Van Essen, et al.) listed in
// the CONTRIBUTORS file. <lbann-dev@llnl.gov>
//
// LLNL-CODE-697807.
// All rights reserved.
//
// This file is part of LBANN: Livermore Big Artificial Neural Network
// Toolkit. For details, see http://software.llnl.gov/LBANN or
// https://github.com/LLNL/LBANN.
//
// Licensed under the Apache License, Version 2.0 (the "Licensee"); you
// may not use this file except in compliance with the License.  You may
// obtain a copy of the License at:
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
// implied. See the License for the specific language governing
// permissions and limitations under the license.
////////////////////////////////////////////////////////////////////////////////

syntax = "proto3";

package lbann_data;

import "datatype.proto";

import "callbacks.proto";

message Trainer {

  // Unique identifier
  string name = 1;

  // Parallel processes per trainer
  //
  // The number of processes per trainer must evenly divide the total
  // number of MPI ranks. The number of resulting trainers is
  // num_procs / procs_per_trainer.
  //
  // If procs_per_trainer is not provided, then all MPI ranks are
  // assigned to one trainer.
  int64 procs_per_trainer = 2;

  // I/O threads per parallel process
  //
  // These threads are typically used to perform data ingestion in the
  // background.
  int64 num_parallel_readers = 3;

  repeated Callback callback = 20;
  int64 mini_batch_size = 12;

  // -------------------------------
  // Advanced options
  // -------------------------------

  // BVE FIXME these should go away
  bool shareable_training_data_reader = 42; // Can the data reader be shared across multiple models( e.g. GAN)
  bool shareable_testing_data_reader = 43; // Can the data reader be shared across multiple models (e.g. GAN)
  bool shareable_validation_data_reader = 44; // Can the data reader be shared across multiple models (e.g. GAN)

  // If false, trainers will have their trainer rank mixed into their random seed.
  bool random_init_trainers_identically = 4;

  // Set a random seed for the entire trainer
  int64 random_seed = 30;

  // Algorithmic block size for Hydrogen
  int64 hydrogen_block_size = 100;

  DataCoordinator data_coordinator = 200;

  message DataCoordinator {
    DataType datatype = 1;
    string io_buffer = 2;         // Options: "partitioned" (default)
  }
}
